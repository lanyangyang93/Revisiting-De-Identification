--optimizer
AdamW
--scheduler
LinearDecayWithWarmup
--num_epochs
40
--lr
1e-4
--batch_size
32
--num_grad_acc_steps
8
--grad_clip
-1
--bert_arch
BERT_base
--bert_drop_rate
0.1
